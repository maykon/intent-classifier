{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intent_classification_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maykon/intent-classifier/blob/master/Intent_classification_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_WypuUXi92e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import RSLPStemmer\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE6wywJrN2ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(filename):\n",
        "  df = pd.read_csv(filename, encoding = 'utf-8', names = [\"Sentence\", \"Intent\"])\n",
        "  print(df.head())\n",
        "  intent = df[\"Intent\"]\n",
        "  unique_intent = list(set(intent))\n",
        "  sentences = list(df[\"Sentence\"])\n",
        "  \n",
        "  return (intent, unique_intent, sentences)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF0FQA7gjOCX",
        "colab_type": "code",
        "outputId": "8656c183-d654-4f11-bb94-e06bf5669330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "intent, unique_intent, sentences = load_dataset(\"Dataset_pt.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                              Sentence       Intent\n",
            "0                        Frete grátis?  FreteGratis\n",
            "1                   Quanto tá o frete?   DadosFrete\n",
            "2  qual o valor do frete para maringá?   DadosFrete\n",
            "3       quanto ta o frete pra maringá?   DadosFrete\n",
            "4        quanto ta o frte para maringá   DadosFrete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8LLUZlokg0S",
        "colab_type": "code",
        "outputId": "2c3832bd-c5b7-4906-bd7f-77a35069e6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sentences[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Frete grátis?', 'Quanto tá o frete?', 'qual o valor do frete para maringá?', 'quanto ta o frete pra maringá?', 'quanto ta o frte para maringá']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhrziINPGHbW",
        "colab_type": "code",
        "outputId": "1ee0dbb0-0ac4-4241-b1af-0137fcd60800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('rslp')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmNLu2YSXePb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define stemmer\n",
        "stemmer = RSLPStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-7q3iG5PKYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleaning(sentences):\n",
        "  words = []\n",
        "  for s in sentences:\n",
        "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", s)\n",
        "    w = word_tokenize(clean, language='portuguese')\n",
        "    #stemming\n",
        "    words.append([stemmer.stem(i.lower()) for i in w])\n",
        "    \n",
        "  return words  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1j2GJgDG6qj",
        "colab_type": "code",
        "outputId": "b4a5b90d-5151-4996-f687-b3fa936089ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cleaned_words = cleaning(sentences)\n",
        "print(len(cleaned_words))\n",
        "print(cleaned_words[:2])  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "[['fret', 'gr', 'ti'], ['quant', 't', 'o', 'fret']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJCQ_YhBJW7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
        "  token = Tokenizer(filters = filters)\n",
        "  token.fit_on_texts(words)\n",
        "  return token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJhdIJC5Q3Q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(words):\n",
        "  return(len(max(words, key = len)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWjxPGsZZJNX",
        "colab_type": "code",
        "outputId": "40d92393-72da-4e1e-ad55-f21472cbebb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_tokenizer = create_tokenizer(cleaned_words)\n",
        "vocab_size = len(word_tokenizer.word_index) + 1\n",
        "max_length = max_length(cleaned_words)\n",
        "\n",
        "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab Size = 69 and Maximum length = 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0TXu2xsR8jq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoding_doc(token, words):\n",
        "  return(token.texts_to_sequences(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE92Hk1Va--H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyOzLEboc4LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padding_doc(encoded_doc, max_length):\n",
        "  return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdejoJrlc-tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_doc = padding_doc(encoded_doc, max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDgTCS2KdI2p",
        "colab_type": "code",
        "outputId": "d669b4b2-6cb4-420f-d0ec-8c35b1e845ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "padded_doc[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2,  6,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 4, 20,  1,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [21,  1, 31, 32,  2,  5,  8,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 4, 10,  1,  2, 11,  8,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 4, 10,  1, 33,  5,  8,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eaSIDi0dNf1",
        "colab_type": "code",
        "outputId": "37eefb2d-4b44-4d52-a81c-f2ff2a189e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Shape of padded docs = \",padded_doc.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of padded docs =  (32, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0rXzenSpgFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer with filter changed\n",
        "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNHQtkszskxr",
        "colab_type": "code",
        "outputId": "0491078c-b570-4760-8cf3-6935a76475ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dadosfrete': 2, 'dadosnotafiscal': 1, 'fretegratis': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OOx9qdBto1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_output = encoding_doc(output_tokenizer, intent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_5Lv5PiyG-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpM86WrVQlx5",
        "colab_type": "code",
        "outputId": "2bf43233-4ab8-43b5-e918-b8439a0d9cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoded_output.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD3QN-RPzfet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(encode):\n",
        "  o = OneHotEncoder(sparse = False)\n",
        "  return(o.fit_transform(encode))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6wP_Xed7RNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_one_hot = one_hot(encoded_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6HVslLTHgOM",
        "colab_type": "code",
        "outputId": "ab431752-2ac9-4027-8b9b-96b2c46a2fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_one_hot.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqABUESD7xi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8P4HTz6A4E-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E0uhC2OCtTx",
        "colab_type": "code",
        "outputId": "726e40ab-37f6-40d4-ff7c-f217763719f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
        "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train_X = (25, 14) and train_Y = (25, 3)\n",
            "Shape of val_X = (7, 14) and val_Y = (7, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5BU_x74DNEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(vocab_size, max_length):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = False))\n",
        "  model.add(Bidirectional(LSTM(128)))\n",
        "#   model.add(LSTM(128))\n",
        "  model.add(Dense(20, activation = \"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(3, activation = \"softmax\"))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-NvE0P7MFCe",
        "colab_type": "code",
        "outputId": "1c2c7bc9-9aae-4520-a9ba-9789e30855ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = create_model(vocab_size, max_length)\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 14, 128)           8832      \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 256)               263168    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 20)                5140      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 3)                 63        \n",
            "=================================================================\n",
            "Total params: 277,203\n",
            "Trainable params: 268,371\n",
            "Non-trainable params: 8,832\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r-dxm2sMQ-d",
        "colab_type": "code",
        "outputId": "4c8edc7f-fe7b-4e24-a374-c9caec3dbdfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filename = 'model.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "hist = model.fit(train_X, train_Y, epochs = 50, batch_size = 10, validation_data = (val_X, val_Y), callbacks = [checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25 samples, validate on 7 samples\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 5s 185ms/step - loss: 1.1026 - acc: 0.2400 - val_loss: 1.0968 - val_acc: 0.1429\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.09680, saving model to model.h5\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 1.0940 - acc: 0.2800 - val_loss: 1.0885 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.09680 to 1.08850, saving model to model.h5\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 1.0743 - acc: 0.4800 - val_loss: 1.0840 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.08850 to 1.08401, saving model to model.h5\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 1.0731 - acc: 0.3600 - val_loss: 1.0782 - val_acc: 0.4286\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.08401 to 1.07817, saving model to model.h5\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 1.0412 - acc: 0.5200 - val_loss: 1.0680 - val_acc: 0.4286\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.07817 to 1.06801, saving model to model.h5\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 1.0105 - acc: 0.5600 - val_loss: 1.0603 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.06801 to 1.06029, saving model to model.h5\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.9773 - acc: 0.6400 - val_loss: 1.0562 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.06029 to 1.05624, saving model to model.h5\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.9186 - acc: 0.7200 - val_loss: 1.0583 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.05624\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 1.1385 - acc: 0.4000 - val_loss: 1.0346 - val_acc: 0.4286\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.05624 to 1.03464, saving model to model.h5\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.9291 - acc: 0.5600 - val_loss: 1.0205 - val_acc: 0.4286\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.03464 to 1.02052, saving model to model.h5\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.8764 - acc: 0.6800 - val_loss: 1.0049 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.02052 to 1.00488, saving model to model.h5\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.8152 - acc: 0.6400 - val_loss: 0.9865 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.00488 to 0.98655, saving model to model.h5\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.9351 - acc: 0.4800 - val_loss: 0.9684 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.98655 to 0.96842, saving model to model.h5\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.9180 - acc: 0.4800 - val_loss: 0.9755 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.96842\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.7785 - acc: 0.7200 - val_loss: 0.9233 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.96842 to 0.92330, saving model to model.h5\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.7496 - acc: 0.6400 - val_loss: 0.8719 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.92330 to 0.87192, saving model to model.h5\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.7340 - acc: 0.6800 - val_loss: 1.0289 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.87192\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6703 - acc: 0.6400 - val_loss: 1.0919 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.87192\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6958 - acc: 0.6800 - val_loss: 0.8678 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.87192 to 0.86775, saving model to model.h5\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5860 - acc: 0.7200 - val_loss: 0.6758 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.86775 to 0.67576, saving model to model.h5\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5231 - acc: 0.7200 - val_loss: 0.8242 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.67576\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4901 - acc: 0.7200 - val_loss: 0.9744 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.67576\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4831 - acc: 0.6800 - val_loss: 1.0500 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.67576\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5551 - acc: 0.6400 - val_loss: 0.9593 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.67576\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5177 - acc: 0.6800 - val_loss: 0.8435 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.67576\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5209 - acc: 0.7600 - val_loss: 0.5443 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.67576 to 0.54428, saving model to model.h5\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4994 - acc: 0.7200 - val_loss: 0.4378 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.54428 to 0.43782, saving model to model.h5\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5625 - acc: 0.7200 - val_loss: 0.4086 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.43782 to 0.40859, saving model to model.h5\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5091 - acc: 0.6800 - val_loss: 0.4122 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.40859\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4891 - acc: 0.7600 - val_loss: 0.4176 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.40859\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4441 - acc: 0.7600 - val_loss: 0.4254 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.40859\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4855 - acc: 0.7200 - val_loss: 0.4288 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.40859\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4129 - acc: 0.6800 - val_loss: 0.4299 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.40859\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4405 - acc: 0.7200 - val_loss: 0.4407 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.40859\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4751 - acc: 0.7200 - val_loss: 0.4619 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.40859\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4493 - acc: 0.8000 - val_loss: 0.4663 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.40859\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4697 - acc: 0.7200 - val_loss: 0.4747 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.40859\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.5085 - acc: 0.6800 - val_loss: 0.4883 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.40859\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4396 - acc: 0.7600 - val_loss: 0.5012 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.40859\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4437 - acc: 0.6800 - val_loss: 0.5184 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.40859\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4115 - acc: 0.7200 - val_loss: 0.6470 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.40859\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4371 - acc: 0.8000 - val_loss: 1.1424 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.40859\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3513 - acc: 0.8800 - val_loss: 0.5761 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.40859\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3631 - acc: 0.8800 - val_loss: 0.4545 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.40859\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4053 - acc: 0.8000 - val_loss: 0.3990 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.40859 to 0.39905, saving model to model.h5\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4617 - acc: 0.7200 - val_loss: 0.4191 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.39905\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4073 - acc: 0.7200 - val_loss: 0.4612 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.39905\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4704 - acc: 0.7200 - val_loss: 0.5128 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.39905\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4775 - acc: 0.6800 - val_loss: 0.4479 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.39905\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4221 - acc: 0.7600 - val_loss: 0.4986 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.39905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjXKos8ocXvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model = load_model(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSTEzrlzcuya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictions(text):\n",
        "  clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
        "  test_word = word_tokenize(clean, language='portuguese')\n",
        "  test_word = [w.lower() for w in test_word]\n",
        "  test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
        "  print(test_word)\n",
        "  #Check for unknown words\n",
        "  if [] in test_ls:\n",
        "    test_ls = list(filter(None, test_ls))\n",
        "    \n",
        "  test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
        " \n",
        "  x = padding_doc(test_ls, max_length)\n",
        "  \n",
        "  pred = model.predict_proba(x)\n",
        "  \n",
        "  \n",
        "  return pred\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1ddofshmdzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_final_output(pred, classes):\n",
        "  predictions = pred[0]\n",
        " \n",
        "  classes = np.array(classes)\n",
        "  ids = np.argsort(-predictions)\n",
        "  classes = classes[ids]\n",
        "  predictions = -np.sort(-predictions)\n",
        " \n",
        "  for i in range(pred.shape[1]):\n",
        "    print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23VpGuihMdEU",
        "colab_type": "code",
        "outputId": "10d2ef60-9db9-47f5-e972-0243af8254ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "text = \"o aviso fala frete gratis.\"\n",
        "pred = predictions(text)\n",
        "get_final_output(pred, unique_intent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['o', 'aviso', 'fala', 'frete', 'gratis']\n",
            "FreteGratis has confidence = 0.54609555\n",
            "DadosFrete has confidence = 0.44028553\n",
            "DadosNotaFiscal has confidence = 0.013618923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKUBDT36IHKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}